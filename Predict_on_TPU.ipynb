{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_on_TPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amplil/Transformer/blob/master/Predict_on_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz5vVeCEg3dQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6125c251-8817-469e-b81d-eee7f27f1fc2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kex5LHlk7Agv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb5ae83-4f5d-44af-ecaf-af61aacff99c"
      },
      "source": [
        "cd \"/content/drive/MyDrive/Colab Notebooks/Transformer\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BIr-qfSPdVd"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/packages\")\n",
        "import slacknotice # オリジナルモジュール slacknotice.send(\"\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x9D7xaiQ1iL"
      },
      "source": [
        "notebook_dir=\"/content/drive/MyDrive/Colab Notebooks/Transformer\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O-5cESj7DxK"
      },
      "source": [
        "# ライブラリ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llf_WS5g7Alo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8501d8f5-ff0b-4917-c211-c8d471d5ee82"
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.6\n",
        "!pip install japanize_matplotlib"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n",
            "Requirement already satisfied: mecab-python3==0.6 in /usr/local/lib/python3.7/dist-packages (0.6)\n",
            "Requirement already satisfied: japanize_matplotlib in /usr/local/lib/python3.7/dist-packages (1.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from japanize_matplotlib) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->japanize_matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcu8U3a07AoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f14848-45b2-4924-8758-e97bd354c0f9"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import MeCab\n",
        "\n",
        "import preprocess_utils\n",
        "import model\n",
        "import weight_utils\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU7TTHws7Hfg"
      },
      "source": [
        "# 日英翻訳データ ダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Wdgxda7ArC"
      },
      "source": [
        "# !wget http://www.manythings.org/anki/jpn-eng.zip\n",
        "# !unzip ./jpn-eng.zip"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nqrPqRH7KRx"
      },
      "source": [
        "# データ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PTyLLU57AzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3034662-6c52-4e38-acb6-53315f655d27"
      },
      "source": [
        "dataset = preprocess_utils.CreateData(\n",
        "    corpus_path = './jpn.txt',\n",
        "    do_shuffle=True,\n",
        "    seed_value=123,\n",
        "    split_percent=0.95 # 学習データの割合\n",
        ")\n",
        "\n",
        "train_source, train_target, test_source, test_target, train_licence, test_licence = dataset.split_data()\n",
        "\n",
        "print('**** Amount of data ****')\n",
        "print('train_source： ', len(train_source))\n",
        "print('train_target： ', len(train_target))\n",
        "print('test_source： ', len(test_source))\n",
        "print('test_target： ', len(test_target))\n",
        "print('\\n')\n",
        "print('**** Train data example ****')\n",
        "print('Source Example： ', train_source[0])\n",
        "print('Target Example： ', train_target[0])\n",
        "print('Licence： ', train_licence[0])\n",
        "print('\\n')\n",
        "print('**** Test data example ****')\n",
        "print('Source Example： ', test_source[0])\n",
        "print('Target Example： ', test_target[0])\n",
        "print('Licence： ', test_licence[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**** Amount of data ****\n",
            "train_source：  72607\n",
            "train_target：  72607\n",
            "test_source：  3821\n",
            "test_target：  3821\n",
            "\n",
            "\n",
            "**** Train data example ****\n",
            "Source Example：  Tom loves Boston.\n",
            "Target Example：  トムはボストンが大好きなんだよ。\n",
            "Licence：  CC-BY 2.0 (France) Attribution: tatoeba.org #6645847 (CK) & #9211042 (small_snow)\n",
            "\n",
            "\n",
            "\n",
            "**** Test data example ****\n",
            "Source Example：  I'm on my way to the station.\n",
            "Target Example：  駅に向かってるとこだよ。\n",
            "Licence：  CC-BY 2.0 (France) Attribution: tatoeba.org #5445615 (CK) & #9281078 (small_snow)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNG8La-07Mzd"
      },
      "source": [
        "# 前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf2N9mWz7A2G"
      },
      "source": [
        "BATCH_SIZE = 64 # バッチサイズ\n",
        "MAX_LENGTH = 60 # シーケンスの長さ\n",
        "USE_TPU = True # TPUを使うか\n",
        "BUFFER_SIZE = 50000"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuNFsYnB7A5N"
      },
      "source": [
        "train_dataset = preprocess_utils.PreprocessData(\n",
        "    mecab = MeCab.Tagger(\"-Ochasen\"),\n",
        "    source_data = train_source,\n",
        "    target_data = train_target,\n",
        "    max_length = MAX_LENGTH,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    test_flag = False,\n",
        "    train_dataset = None,\n",
        ")\n",
        "\n",
        "train_dataset.preprocess_data()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQZaiADz8uOk"
      },
      "source": [
        "test_dataset = preprocess_utils.PreprocessData(\n",
        "    mecab = MeCab.Tagger(\"-Ochasen\"),\n",
        "    source_data = test_source,\n",
        "    target_data = test_target,\n",
        "    max_length = MAX_LENGTH,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    test_flag = True,\n",
        "    train_dataset = train_dataset\n",
        ")\n",
        "\n",
        "test_dataset.preprocess_data()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTZf4AzI7P7o"
      },
      "source": [
        "# バッチ作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2ls-SZK7A7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6642e3ae-96fe-446f-daee-fbe1a9beef55"
      },
      "source": [
        "if USE_TPU:\n",
        "  tpu_grpc_url = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
        "  tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "  tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)    \n",
        "  strategy = tf.distribute.TPUStrategy(tpu_cluster_resolver)\n",
        "\n",
        "trainset = tf.data.Dataset.from_tensor_slices((train_dataset.source_vector, train_dataset.target_vector))\n",
        "trainset = trainset.map(lambda source, target: (tf.cast(source, tf.int64), tf.cast(target, tf.int64))).shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "if USE_TPU:\n",
        "  trainset = strategy.experimental_distribute_dataset(trainset)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.69.120.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.69.120.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.69.120.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.69.120.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFpWc-sg8zFJ"
      },
      "source": [
        "if USE_TPU:\n",
        "  PREDICT_BATCH_SIZE = 8\n",
        "  testset = tf.data.Dataset.from_tensor_slices((test_dataset.source_vector, test_dataset.target_vector))\n",
        "  testset = testset.map(lambda source, target: (tf.cast(source, tf.int64), tf.cast(target, tf.int64))).shuffle(buffer_size=50000).batch(PREDICT_BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  testset = testset.take(1)\n",
        "  testset = strategy.experimental_distribute_dataset(testset)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "171z8b3v7Tmg"
      },
      "source": [
        "# モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC54O3da7A-O"
      },
      "source": [
        "num_layers=4 # レイヤー数\n",
        "d_model=64 # 中間層の次元数\n",
        "num_heads=4 # Multi Head Attentionのヘッド数\n",
        "dff=2048 # Feed Forward Networkの次元数\n",
        "dropout_rate = 0.1 # ドロップアウト率\n",
        "\n",
        "source_vocab_size = max(train_dataset.source_token.values()) + 1 # source文の語彙数\n",
        "target_vocab_size = max(train_dataset.target_token.values()) + 1 # target文の語彙数"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvjwLsmP7BBE"
      },
      "source": [
        "# 重み初期化\n",
        "def initialize_weight(checkpoint_path, optimizer, transformer, max_length, batch_size, use_tpu=False):\n",
        "\n",
        "  if os.path.exists(checkpoint_path+'.pkl'):\n",
        "    if use_tpu:\n",
        "      number_of_tpu_cores = tpu_cluster_resolver.num_accelerators()['TPU']\n",
        "      initialize_source, initialize_target = [[1]*max_length]*number_of_tpu_cores, [[1]*max_length]*number_of_tpu_cores\n",
        "      initialize_set = tf.data.Dataset.from_tensor_slices((initialize_source, initialize_target))\n",
        "      initialize_set = initialize_set.map(lambda source, target: (tf.cast(source, tf.int64), tf.cast(target, tf.int64))\n",
        "          ).shuffle(buffer_size=BUFFER_SIZE).batch(batch_size).prefetch(\n",
        "              buffer_size=tf.data.experimental.AUTOTUNE\n",
        "          )\n",
        "      initialize_set = strategy.experimental_distribute_dataset(initialize_set)\n",
        "\n",
        "      for inp, tar in initialize_set:\n",
        "          distributed_train_step(inp, tar)\n",
        "\n",
        "    else:\n",
        "      initialize_set = tf.ones([batch_size, max_length], tf.int64)\n",
        "      train_step(initialize_set, initialize_set)\n",
        "    \n",
        "    try:\n",
        "      weight_utils.load_weights_from_pickle(checkpoint_path, optimizer, transformer)\n",
        "    except:\n",
        "      print('Failed to load checkpoints.')\n",
        "\n",
        "  else:\n",
        "    print('No available checkpoints.')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw8zmGVk7XQW"
      },
      "source": [
        "# 予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_bnPfZx7BD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efcb697-c03a-4509-e6cd-5b02b53650b3"
      },
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "  # Transformer\n",
        "  transformer = model.Transformer(num_layers, d_model, num_heads, dff,\n",
        "                            source_vocab_size, target_vocab_size, \n",
        "                            pe_input=source_vocab_size, \n",
        "                            pe_target=target_vocab_size,\n",
        "                            rate=dropout_rate)\n",
        "\n",
        "  # Learning Rate\n",
        "  learning_rate = model.CustomSchedule(d_model)\n",
        "\n",
        "  # Optimizer\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                      epsilon=1e-9)\n",
        "\n",
        "  # Loss\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "  # Loss Function\n",
        "  def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "  # Metrics\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "  # Checkpoint\n",
        "  #checkpoint_path = \"/content/drive/My Drive/Transformer-master/checkpoints/tpu/model\"\n",
        "  checkpoint_path = notebook_dir+\"/checkpoints/tpu/model\"\n",
        "\n",
        "  def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "    \n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = model.create_masks(inp, tar_inp)\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions, _ = transformer(inp, tar_inp, \n",
        "                                  True, \n",
        "                                  enc_padding_mask, \n",
        "                                  combined_mask, \n",
        "                                  dec_padding_mask)\n",
        "      loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)\n",
        "\n",
        "  @tf.function\n",
        "  def distributed_train_step(X, y):\n",
        "    per_replica_losses = strategy.run(train_step, args=(X, y))\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
        "\n",
        "  def test_step(inp, tar):\n",
        "      enc_padding_mask, combined_mask, dec_padding_mask = model.create_masks(inp, tar)\n",
        "      \n",
        "      predictions, attention_weights = transformer(inp, tar, \n",
        "                                  False, \n",
        "                                  enc_padding_mask, \n",
        "                                  combined_mask, \n",
        "                                  dec_padding_mask)\n",
        "      \n",
        "      predicted_id = tf.cast(tf.argmax(predictions[: ,-1:, :], axis=-1), tf.int64)\n",
        "      return inp, tf.concat([tar, predicted_id], axis=-1), attention_weights\n",
        "\n",
        "  @tf.function\n",
        "  def distributed_test_step(X, y):\n",
        "        return strategy.experimental_local_results(strategy.run(test_step, args=(X, y)))\n",
        "\n",
        "\n",
        "  # Initialize Weight\n",
        "  initialize_weight(checkpoint_path, optimizer, transformer, MAX_LENGTH, PREDICT_BATCH_SIZE, use_tpu=USE_TPU)\n",
        "\n",
        "  for inp, tar in testset:\n",
        "    for i in range(MAX_LENGTH):\n",
        "        inp, tar, attn = distributed_test_step(inp, tar)[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function distributed_train_step at 0x7fd936d799e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_train_step at 0x7fd936d799e0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function distributed_train_step at 0x7fd936d799e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_train_step at 0x7fd936d799e0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function distributed_train_step at 0x7fd936d799e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_train_step at 0x7fd936d799e0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function train_step at 0x7fd9369bd560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function train_step at 0x7fd9369bd560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function train_step at 0x7fd9369bd560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function train_step at 0x7fd9369bd560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function train_step at 0x7fd9369bd560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function train_step at 0x7fd9369bd560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Load checkpoints successfully.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function distributed_test_step at 0x7fd933ffe5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_test_step at 0x7fd933ffe5f0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function distributed_test_step at 0x7fd933ffe5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_test_step at 0x7fd933ffe5f0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function distributed_test_step at 0x7fd933ffe5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_test_step at 0x7fd933ffe5f0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function test_step at 0x7fd933ffe560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function test_step at 0x7fd933ffe560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function test_step at 0x7fd933ffe560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function test_step at 0x7fd933ffe560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function test_step at 0x7fd933ffe560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function test_step at 0x7fd933ffe560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "CPU times: user 2min 17s, sys: 5.78 s, total: 2min 22s\n",
            "Wall time: 4min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnzYYW2T7BGW"
      },
      "source": [
        "def plot_attention_weight(sentence, attention, result):\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "  for head in range(attention.shape[0]):\n",
        "    ax = fig.add_subplot(2, 4, head+1)\n",
        "    \n",
        "    #ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "    #ax.matshow(attention[head], cmap='viridis')\n",
        "    ax.matshow(attention[head][:-1], cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 10}\n",
        "    \n",
        "    ax.set_xticks(range(len(sentence)))\n",
        "    ax.set_yticks(range(result.shape[0]))\n",
        "    \n",
        "    ax.set_ylim(result.shape[0]-1.5, -0.5)\n",
        "        \n",
        "    tmp_list = []\n",
        "    for i in sentence:\n",
        "      try:\n",
        "        tmp_list.append(train_dataset.source_index[i.numpy()])\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    ax.set_xticklabels(tmp_list, fontdict=fontdict, rotation=90)\n",
        "    \n",
        "    ax.set_yticklabels([train_dataset.target_index[i.numpy()] for i in result \n",
        "                        if i < max(train_dataset.target_token.values()) - 1], \n",
        "                        fontdict=fontdict)\n",
        "    \n",
        "    ax.set_xlabel('Head {}'.format(head+1))\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvUA6oPbbaq-"
      },
      "source": [
        "list(inp.numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpPQKP2NdQaN",
        "outputId": "70e5cf34-87e7-429d-ad4e-eeaeaf87d9c0"
      },
      "source": [
        "attn['decoder_layer4_block2'].numpy()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[4.9053403e-03, 8.8131696e-01, 2.0767043e-03, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [9.1249287e-02, 4.7966123e-01, 7.2611975e-03, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [8.9745218e-04, 1.7907862e-03, 1.2373109e-03, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         ...,\n",
              "         [1.9167602e-01, 2.3094708e-01, 7.5499654e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.3528349e-01, 4.3336622e-02, 5.0182920e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [1.9071960e-01, 2.3323952e-01, 7.5703561e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
              "\n",
              "        [[1.0571907e-01, 1.9614249e-01, 2.5599906e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [1.9177377e-01, 8.2290499e-03, 1.5603602e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [5.5241454e-03, 6.5251491e-03, 4.9397230e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         ...,\n",
              "         [2.6944965e-01, 8.0491435e-03, 6.7288294e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.6914263e-01, 8.3612942e-04, 5.4232553e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.6943719e-01, 8.4068412e-03, 6.7424305e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
              "\n",
              "        [[1.3544545e-01, 4.1742632e-01, 5.0290130e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [5.0736360e-02, 2.7985238e-03, 7.5133079e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.1061486e-02, 5.3259548e-02, 6.3334644e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         ...,\n",
              "         [2.8156859e-01, 1.7014422e-02, 9.7861804e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.7186939e-01, 3.7280093e-03, 2.7268499e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.8285551e-01, 1.7560184e-02, 9.4911598e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
              "\n",
              "        [[3.1554256e-07, 9.9999762e-01, 1.4504272e-07, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.3379064e-01, 1.5499747e-03, 1.9014435e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.1011203e-03, 2.7849892e-04, 7.3689944e-03, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         ...,\n",
              "         [2.7333501e-01, 4.7452431e-02, 1.4030750e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.7026236e-01, 1.4228979e-06, 2.7578237e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.7296451e-01, 4.4920430e-02, 1.4054933e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvLnI2I2b3GR"
      },
      "source": [
        "list(zip(inp.numpy(), tar.numpy(), attn['decoder_layer4_block2'].numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_WA03K04bYV4",
        "outputId": "41ee9af5-74b2-43f4-a752-36c829281732"
      },
      "source": [
        "inp.values"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-9f00ab6130cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GFqwMspeakl",
        "outputId": "bd9924cc-e0b2-48ae-ae6f-61cc3c9c0da1"
      },
      "source": [
        "sentence"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=int64, numpy=array([11453,     1,  1417,    25,   730,     4, 11454])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjszRaeOe9pd",
        "outputId": "c385fbde-a873-4b4e-e847-5895d630c350"
      },
      "source": [
        "sentence.shape[0]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD01L89YfDb9"
      },
      "source": [
        "a[0,:, :sentence.shape[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su6JX2lfgE6-",
        "outputId": "670c21cc-9cf1-4795-ca2c-440fe8346df1"
      },
      "source": [
        "attention.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGG9OL95giSE",
        "outputId": "1e13863c-ae72-45a1-f20e-3fb5d1963ead"
      },
      "source": [
        "attention[7]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3755067 , 0.01035687, 0.10788263, 0.14881349, 0.0342859 ,\n",
              "       0.21384533, 0.10930903], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj2wSUIQf5x3",
        "outputId": "cc508070-1fcf-4b9c-f024-d7cc7856f584"
      },
      "source": [
        "attention[7][:-1]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3755067 , 0.01035687, 0.10788263, 0.14881349, 0.0342859 ,\n",
              "       0.21384533], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE9xFuQ-h9gB",
        "outputId": "ca8bbeb8-24fe-4d56-a6f5-fd1f8ed23d29"
      },
      "source": [
        "result.numpy()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    1,     2,   728,     4,  6624,   135,    20,     9,    10,\n",
              "       16256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so2Gfe1bioK3",
        "outputId": "2be1a4d7-8789-4a35-ea78-24dc9099138d"
      },
      "source": [
        "len(attention)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzZLz5QOkQjd",
        "outputId": "c8c19f84-6d3c-4779-baa4-41e5e0d2b2e7"
      },
      "source": [
        "attention.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k4G_wmykadU",
        "outputId": "3afb0519-1bce-4ddf-e581-1b59de23bf0a"
      },
      "source": [
        "sentence.shape"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Udap8Suu7N",
        "outputId": "7dd6114c-39d1-431e-9643-ed5e42091b5e"
      },
      "source": [
        "result.shape"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV7xe5rillZ8",
        "outputId": "9923afec-d708-4352-9083-884268b5a75a"
      },
      "source": [
        "inp.numpy()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11453,     1,  1417,    25,   730,     4, 11454,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUywUhVlZeG"
      },
      "source": [
        "list(enumerate(zip(inp.numpy(), tar.numpy(), attn['decoder_layer4_block2'].numpy())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "xWvgga_MlFED",
        "outputId": "dbccc124-d545-45f2-fea7-54e4adb55ed9"
      },
      "source": [
        "len(list(enumerate(zip(inp.numpy(), tar.numpy(), attn['decoder_layer4_block2'].numpy())))[0][0])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-b8ab4bfc0f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_layer4_block2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAIK89nbmFR6"
      },
      "source": [
        " a[0,:, :sentence.shape[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SnoI0iRpXBr",
        "outputId": "31e0bcf3-1861-4320-887d-1476347d54c2"
      },
      "source": [
        "attention[0]"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00490534, 0.88131696, 0.0020767 , 0.00346318, 0.10490883,\n",
              "       0.002082  , 0.00124701, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fF8cnsOtujsZ",
        "outputId": "1940309e-237c-439f-d888-5750625417bd"
      },
      "source": [
        "attention.shape"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-79bf50f4aea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;31m# `_tensor_shape` is declared and defined in the definition of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;31m# `EagerTensor`, in C.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 3; input has only 3 dims"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqciGsXVu9Pl",
        "outputId": "3207cf74-f167-4788-a775-a4c0a669ca3a"
      },
      "source": [
        "attn['decoder_layer4_block2'].numpy()[0,:, :sentence.shape[0]].shape"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 7, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiL2nXPgvyyg",
        "outputId": "47764e4a-20a1-44aa-8624-9bdd10fd1c20"
      },
      "source": [
        "sentence.shape"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMFL3SO5qavC",
        "outputId": "3a5983e0-ad9b-44a3-b4d3-341ada92871c"
      },
      "source": [
        "sentence"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=int64, numpy=array([11453,     1,  1417,    25,   730,     4, 11454])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "xPk87O9Fv70v",
        "outputId": "a09ea8d8-0ed1-4c0d-c203-ed679a743842"
      },
      "source": [
        "for i, (s, t, a) in enumerate(zip(inp, tar, attn['decoder_layer4_block2'])):\n",
        "  sentence = tf.squeeze(s)[:tf.argmax(tf.squeeze(s)).numpy()+1]\n",
        "  attention = a[0,:,:, :sentence.shape[0]]\n",
        "  #attention = a[0, :sentence.shape[0]]\n",
        "\n",
        "  result = tf.squeeze(t)[:tf.argmax(tf.squeeze(t)).numpy()+1][1:]\n",
        "  print(\"Input:\", ' '.join([train_dataset.source_index[i.numpy()] for i in sentence][1:-1]))\n",
        "  print(\"Output:\", ''.join([train_dataset.target_index[i.numpy()] for i in result][:-1]))\n",
        "  plot_attention_weight(sentence, attention, result)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Tom wants a cat .\n",
            "Output: トムは猫が飼いたいのよ。\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-c7def4cbc454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mplot_attention_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-106-93b301d94915>\u001b[0m in \u001b[0;36mplot_attention_weight\u001b[0;34m(sentence, attention, result)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;31m# `_tensor_shape` is declared and defined in the definition of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;31m# `EagerTensor`, in C.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 3; input has only 3 dims"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "eQhGAHxecATo",
        "outputId": "3471806b-a399-4e59-e580-dca3e9731844"
      },
      "source": [
        "for i, (s, t, a) in enumerate(zip(inp.numpy(), tar.numpy(), attn['decoder_layer4_block2'].numpy())):\n",
        "  sentence = tf.squeeze(s)[:tf.argmax(tf.squeeze(s)).numpy()+1]\n",
        "  attention = a[0,:, :sentence.shape[0]]\n",
        "  #attention = a[0, :sentence.shape[0]]\n",
        "  result = tf.squeeze(t)[:tf.argmax(tf.squeeze(t)).numpy()+1][1:]\n",
        "  print(\"Input:\", ' '.join([train_dataset.source_index[i.numpy()] for i in sentence][1:-1]))\n",
        "  print(\"Output:\", ''.join([train_dataset.target_index[i.numpy()] for i in result][:-1]))\n",
        "  plot_attention_weight(sentence, attention, result)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Tom wants a cat .\n",
            "Output: トムは猫が飼いたいのよ。\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-839d25e2b0f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mplot_attention_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-106-93b301d94915>\u001b[0m in \u001b[0;36mplot_attention_weight\u001b[0;34m(sentence, attention, result)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#ax.matshow(attention[head][:-1, :], cmap='viridis')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#ax.matshow(attention[head], cmap='viridis')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfontdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'fontsize'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mmatshow\u001b[0;34m(self, Z, **kwargs)\u001b[0m\n\u001b[1;32m   7789\u001b[0m               \u001b[0;34m'aspect'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'equal'\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# (already the imshow default)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7790\u001b[0m               **kwargs}\n\u001b[0;32m-> 7791\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7792\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7793\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (6,) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMR8Z_lpLEpg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "7e0c1953-0f90-44e4-ad60-f681d612f50a"
      },
      "source": [
        "for i, (s, t, a) in enumerate(zip(inp.values, tar.values, attn['decoder_layer4_block2'].values)):\n",
        "  sentence = tf.squeeze(s)[:tf.argmax(tf.squeeze(s)).numpy()+1]\n",
        "  attention = a[0,:, :, :sentence.shape[0]]\n",
        "  result = tf.squeeze(t)[:tf.argmax(tf.squeeze(t)).numpy()+1][1:]\n",
        "  print(\"Input:\", ' '.join([train_dataset.source_index[i.numpy()] for i in sentence][1:-1]))\n",
        "  print(\"Output:\", ''.join([train_dataset.target_index[i.numpy()] for i in result][:-1]))\n",
        "  plot_attention_weight(sentence, attention, result)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-52cf15020101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_layer4_block2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'values'"
          ]
        }
      ]
    }
  ]
}