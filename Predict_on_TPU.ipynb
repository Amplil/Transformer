{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_on_TPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amplil/Transformer/blob/master/Predict_on_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz5vVeCEg3dQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6125c251-8817-469e-b81d-eee7f27f1fc2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kex5LHlk7Agv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb5ae83-4f5d-44af-ecaf-af61aacff99c"
      },
      "source": [
        "cd \"/content/drive/MyDrive/Colab Notebooks/Transformer\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BIr-qfSPdVd"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/packages\")\n",
        "import slacknotice # オリジナルモジュール slacknotice.send(\"\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x9D7xaiQ1iL"
      },
      "source": [
        "notebook_dir=\"/content/drive/MyDrive/Colab Notebooks/Transformer\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O-5cESj7DxK"
      },
      "source": [
        "# ライブラリ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llf_WS5g7Alo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8501d8f5-ff0b-4917-c211-c8d471d5ee82"
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.6\n",
        "!pip install japanize_matplotlib"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.8)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.13)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n",
            "Requirement already satisfied: mecab-python3==0.6 in /usr/local/lib/python3.7/dist-packages (0.6)\n",
            "Requirement already satisfied: japanize_matplotlib in /usr/local/lib/python3.7/dist-packages (1.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from japanize_matplotlib) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->japanize_matplotlib) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->japanize_matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcu8U3a07AoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f14848-45b2-4924-8758-e97bd354c0f9"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import MeCab\n",
        "\n",
        "import preprocess_utils\n",
        "import model\n",
        "import weight_utils\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU7TTHws7Hfg"
      },
      "source": [
        "# 日英翻訳データ ダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Wdgxda7ArC"
      },
      "source": [
        "# !wget http://www.manythings.org/anki/jpn-eng.zip\n",
        "# !unzip ./jpn-eng.zip"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nqrPqRH7KRx"
      },
      "source": [
        "# データ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PTyLLU57AzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3034662-6c52-4e38-acb6-53315f655d27"
      },
      "source": [
        "dataset = preprocess_utils.CreateData(\n",
        "    corpus_path = './jpn.txt',\n",
        "    do_shuffle=True,\n",
        "    seed_value=123,\n",
        "    split_percent=0.95 # 学習データの割合\n",
        ")\n",
        "\n",
        "train_source, train_target, test_source, test_target, train_licence, test_licence = dataset.split_data()\n",
        "\n",
        "print('**** Amount of data ****')\n",
        "print('train_source： ', len(train_source))\n",
        "print('train_target： ', len(train_target))\n",
        "print('test_source： ', len(test_source))\n",
        "print('test_target： ', len(test_target))\n",
        "print('\\n')\n",
        "print('**** Train data example ****')\n",
        "print('Source Example： ', train_source[0])\n",
        "print('Target Example： ', train_target[0])\n",
        "print('Licence： ', train_licence[0])\n",
        "print('\\n')\n",
        "print('**** Test data example ****')\n",
        "print('Source Example： ', test_source[0])\n",
        "print('Target Example： ', test_target[0])\n",
        "print('Licence： ', test_licence[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**** Amount of data ****\n",
            "train_source：  72607\n",
            "train_target：  72607\n",
            "test_source：  3821\n",
            "test_target：  3821\n",
            "\n",
            "\n",
            "**** Train data example ****\n",
            "Source Example：  Tom loves Boston.\n",
            "Target Example：  トムはボストンが大好きなんだよ。\n",
            "Licence：  CC-BY 2.0 (France) Attribution: tatoeba.org #6645847 (CK) & #9211042 (small_snow)\n",
            "\n",
            "\n",
            "\n",
            "**** Test data example ****\n",
            "Source Example：  I'm on my way to the station.\n",
            "Target Example：  駅に向かってるとこだよ。\n",
            "Licence：  CC-BY 2.0 (France) Attribution: tatoeba.org #5445615 (CK) & #9281078 (small_snow)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNG8La-07Mzd"
      },
      "source": [
        "# 前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf2N9mWz7A2G"
      },
      "source": [
        "BATCH_SIZE = 64 # バッチサイズ\n",
        "MAX_LENGTH = 60 # シーケンスの長さ\n",
        "USE_TPU = True # TPUを使うか\n",
        "BUFFER_SIZE = 50000"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuNFsYnB7A5N"
      },
      "source": [
        "train_dataset = preprocess_utils.PreprocessData(\n",
        "    mecab = MeCab.Tagger(\"-Ochasen\"),\n",
        "    source_data = train_source,\n",
        "    target_data = train_target,\n",
        "    max_length = MAX_LENGTH,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    test_flag = False,\n",
        "    train_dataset = None,\n",
        ")\n",
        "\n",
        "train_dataset.preprocess_data()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQZaiADz8uOk"
      },
      "source": [
        "test_dataset = preprocess_utils.PreprocessData(\n",
        "    mecab = MeCab.Tagger(\"-Ochasen\"),\n",
        "    source_data = test_source,\n",
        "    target_data = test_target,\n",
        "    max_length = MAX_LENGTH,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    test_flag = True,\n",
        "    train_dataset = train_dataset\n",
        ")\n",
        "\n",
        "test_dataset.preprocess_data()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTZf4AzI7P7o"
      },
      "source": [
        "# バッチ作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2ls-SZK7A7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6642e3ae-96fe-446f-daee-fbe1a9beef55"
      },
      "source": [
        "if USE_TPU:\n",
        "  tpu_grpc_url = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
        "  tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "  tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)    \n",
        "  strategy = tf.distribute.TPUStrategy(tpu_cluster_resolver)\n",
        "\n",
        "trainset = tf.data.Dataset.from_tensor_slices((train_dataset.source_vector, train_dataset.target_vector))\n",
        "trainset = trainset.map(lambda source, target: (tf.cast(source, tf.int64), tf.cast(target, tf.int64))).shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "if USE_TPU:\n",
        "  trainset = strategy.experimental_distribute_dataset(trainset)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.69.120.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.69.120.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.69.120.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.69.120.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFpWc-sg8zFJ"
      },
      "source": [
        "if USE_TPU:\n",
        "  PREDICT_BATCH_SIZE = 8\n",
        "  testset = tf.data.Dataset.from_tensor_slices((test_dataset.source_vector, test_dataset.target_vector))\n",
        "  testset = testset.map(lambda source, target: (tf.cast(source, tf.int64), tf.cast(target, tf.int64))).shuffle(buffer_size=50000).batch(PREDICT_BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  testset = testset.take(1)\n",
        "  testset = strategy.experimental_distribute_dataset(testset)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "171z8b3v7Tmg"
      },
      "source": [
        "# モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC54O3da7A-O"
      },
      "source": [
        "num_layers=4 # レイヤー数\n",
        "d_model=64 # 中間層の次元数\n",
        "num_heads=4 # Multi Head Attentionのヘッド数\n",
        "dff=2048 # Feed Forward Networkの次元数\n",
        "dropout_rate = 0.1 # ドロップアウト率\n",
        "\n",
        "source_vocab_size = max(train_dataset.source_token.values()) + 1 # source文の語彙数\n",
        "target_vocab_size = max(train_dataset.target_token.values()) + 1 # target文の語彙数"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvjwLsmP7BBE"
      },
      "source": [
        "# 重み初期化\n",
        "def initialize_weight(checkpoint_path, optimizer, transformer, max_length, batch_size, use_tpu=False):\n",
        "\n",
        "  if os.path.exists(checkpoint_path+'.pkl'):\n",
        "    if use_tpu:\n",
        "      number_of_tpu_cores = tpu_cluster_resolver.num_accelerators()['TPU']\n",
        "      initialize_source, initialize_target = [[1]*max_length]*number_of_tpu_cores, [[1]*max_length]*number_of_tpu_cores\n",
        "      initialize_set = tf.data.Dataset.from_tensor_slices((initialize_source, initialize_target))\n",
        "      initialize_set = initialize_set.map(lambda source, target: (tf.cast(source, tf.int64), tf.cast(target, tf.int64))\n",
        "          ).shuffle(buffer_size=BUFFER_SIZE).batch(batch_size).prefetch(\n",
        "              buffer_size=tf.data.experimental.AUTOTUNE\n",
        "          )\n",
        "      initialize_set = strategy.experimental_distribute_dataset(initialize_set)\n",
        "\n",
        "      for inp, tar in initialize_set:\n",
        "          distributed_train_step(inp, tar)\n",
        "\n",
        "    else:\n",
        "      initialize_set = tf.ones([batch_size, max_length], tf.int64)\n",
        "      train_step(initialize_set, initialize_set)\n",
        "    \n",
        "    try:\n",
        "      weight_utils.load_weights_from_pickle(checkpoint_path, optimizer, transformer)\n",
        "    except:\n",
        "      print('Failed to load checkpoints.')\n",
        "\n",
        "  else:\n",
        "    print('No available checkpoints.')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw8zmGVk7XQW"
      },
      "source": [
        "# 予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_bnPfZx7BD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efcb697-c03a-4509-e6cd-5b02b53650b3"
      },
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "  # Transformer\n",
        "  transformer = model.Transformer(num_layers, d_model, num_heads, dff,\n",
        "                            source_vocab_size, target_vocab_size, \n",
        "                            pe_input=source_vocab_size, \n",
        "                            pe_target=target_vocab_size,\n",
        "                            rate=dropout_rate)\n",
        "\n",
        "  # Learning Rate\n",
        "  learning_rate = model.CustomSchedule(d_model)\n",
        "\n",
        "  # Optimizer\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                      epsilon=1e-9)\n",
        "\n",
        "  # Loss\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "  # Loss Function\n",
        "  def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "  # Metrics\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "  # Checkpoint\n",
        "  #checkpoint_path = \"/content/drive/My Drive/Transformer-master/checkpoints/tpu/model\"\n",
        "  checkpoint_path = notebook_dir+\"/checkpoints/tpu/model\"\n",
        "\n",
        "  def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "    \n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = model.create_masks(inp, tar_inp)\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions, _ = transformer(inp, tar_inp, \n",
        "                                  True, \n",
        "                                  enc_padding_mask, \n",
        "                                  combined_mask, \n",
        "                                  dec_padding_mask)\n",
        "      loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)\n",
        "\n",
        "  @tf.function\n",
        "  def distributed_train_step(X, y):\n",
        "    per_replica_losses = strategy.run(train_step, args=(X, y))\n",
        "    return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n",
        "\n",
        "  def test_step(inp, tar):\n",
        "      enc_padding_mask, combined_mask, dec_padding_mask = model.create_masks(inp, tar)\n",
        "      \n",
        "      predictions, attention_weights = transformer(inp, tar, \n",
        "                                  False, \n",
        "                                  enc_padding_mask, \n",
        "                                  combined_mask, \n",
        "                                  dec_padding_mask)\n",
        "      \n",
        "      predicted_id = tf.cast(tf.argmax(predictions[: ,-1:, :], axis=-1), tf.int64)\n",
        "      return inp, tf.concat([tar, predicted_id], axis=-1), attention_weights\n",
        "\n",
        "  @tf.function\n",
        "  def distributed_test_step(X, y):\n",
        "        return strategy.experimental_local_results(strategy.run(test_step, args=(X, y)))\n",
        "\n",
        "\n",
        "  # Initialize Weight\n",
        "  initialize_weight(checkpoint_path, optimizer, transformer, MAX_LENGTH, PREDICT_BATCH_SIZE, use_tpu=USE_TPU)\n",
        "\n",
        "  for inp, tar in testset:\n",
        "    for i in range(MAX_LENGTH):\n",
        "        inp, tar, attn = distributed_test_step(inp, tar)[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function distributed_train_step at 0x7fd936d799e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_train_step at 0x7fd936d799e0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function distributed_train_step at 0x7fd936d799e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_train_step at 0x7fd936d799e0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function distributed_train_step at 0x7fd936d799e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_train_step at 0x7fd936d799e0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function train_step at 0x7fd9369bd560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function train_step at 0x7fd9369bd560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function train_step at 0x7fd9369bd560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function train_step at 0x7fd9369bd560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function train_step at 0x7fd9369bd560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function train_step at 0x7fd9369bd560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Load checkpoints successfully.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function distributed_test_step at 0x7fd933ffe5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_test_step at 0x7fd933ffe5f0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function distributed_test_step at 0x7fd933ffe5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_test_step at 0x7fd933ffe5f0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function distributed_test_step at 0x7fd933ffe5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function distributed_test_step at 0x7fd933ffe5f0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function test_step at 0x7fd933ffe560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function test_step at 0x7fd933ffe560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function test_step at 0x7fd933ffe560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function test_step at 0x7fd933ffe560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function test_step at 0x7fd933ffe560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <function test_step at 0x7fd933ffe560>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "CPU times: user 2min 17s, sys: 5.78 s, total: 2min 22s\n",
            "Wall time: 4min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnzYYW2T7BGW"
      },
      "source": [
        "def plot_attention_weight(sentence, attention, result):\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "  for head in range(attention.shape[0]):\n",
        "    ax = fig.add_subplot(2, 4, head+1)\n",
        "    \n",
        "    #ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "    #ax.matshow(attention[head], cmap='viridis')\n",
        "    ax.matshow(attention[head][:-1], cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 10}\n",
        "    \n",
        "    ax.set_xticks(range(len(sentence)))\n",
        "    ax.set_yticks(range(result.shape[0]))\n",
        "    \n",
        "    ax.set_ylim(result.shape[0]-1.5, -0.5)\n",
        "        \n",
        "    tmp_list = []\n",
        "    for i in sentence:\n",
        "      try:\n",
        "        tmp_list.append(train_dataset.source_index[i.numpy()])\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    ax.set_xticklabels(tmp_list, fontdict=fontdict, rotation=90)\n",
        "    \n",
        "    ax.set_yticklabels([train_dataset.target_index[i.numpy()] for i in result \n",
        "                        if i < max(train_dataset.target_token.values()) - 1], \n",
        "                        fontdict=fontdict)\n",
        "    \n",
        "    ax.set_xlabel('Head {}'.format(head+1))\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvUA6oPbbaq-"
      },
      "source": [
        "list(inp.numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpPQKP2NdQaN",
        "outputId": "70e5cf34-87e7-429d-ad4e-eeaeaf87d9c0"
      },
      "source": [
        "attn['decoder_layer4_block2'].numpy()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[4.9053403e-03, 8.8131696e-01, 2.0767043e-03, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [9.1249287e-02, 4.7966123e-01, 7.2611975e-03, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [8.9745218e-04, 1.7907862e-03, 1.2373109e-03, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         ...,\n",
              "         [1.9167602e-01, 2.3094708e-01, 7.5499654e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.3528349e-01, 4.3336622e-02, 5.0182920e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [1.9071960e-01, 2.3323952e-01, 7.5703561e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
              "\n",
              "        [[1.0571907e-01, 1.9614249e-01, 2.5599906e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [1.9177377e-01, 8.2290499e-03, 1.5603602e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [5.5241454e-03, 6.5251491e-03, 4.9397230e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         ...,\n",
              "         [2.6944965e-01, 8.0491435e-03, 6.7288294e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.6914263e-01, 8.3612942e-04, 5.4232553e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.6943719e-01, 8.4068412e-03, 6.7424305e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
              "\n",
              "        [[1.3544545e-01, 4.1742632e-01, 5.0290130e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [5.0736360e-02, 2.7985238e-03, 7.5133079e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.1061486e-02, 5.3259548e-02, 6.3334644e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         ...,\n",
              "         [2.8156859e-01, 1.7014422e-02, 9.7861804e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.7186939e-01, 3.7280093e-03, 2.7268499e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.8285551e-01, 1.7560184e-02, 9.4911598e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
              "\n",
              "        [[3.1554256e-07, 9.9999762e-01, 1.4504272e-07, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.3379064e-01, 1.5499747e-03, 1.9014435e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.1011203e-03, 2.7849892e-04, 7.3689944e-03, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         ...,\n",
              "         [2.7333501e-01, 4.7452431e-02, 1.4030750e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.7026236e-01, 1.4228979e-06, 2.7578237e-02, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "         [2.7296451e-01, 4.4920430e-02, 1.4054933e-01, ...,\n",
              "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvLnI2I2b3GR"
      },
      "source": [
        "list(zip(inp.numpy(), tar.numpy(), attn['decoder_layer4_block2'].numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_WA03K04bYV4",
        "outputId": "41ee9af5-74b2-43f4-a752-36c829281732"
      },
      "source": [
        "inp.values"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-9f00ab6130cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GFqwMspeakl",
        "outputId": "bd9924cc-e0b2-48ae-ae6f-61cc3c9c0da1"
      },
      "source": [
        "sentence"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=int64, numpy=array([11453,     1,  1417,    25,   730,     4, 11454])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjszRaeOe9pd",
        "outputId": "c385fbde-a873-4b4e-e847-5895d630c350"
      },
      "source": [
        "sentence.shape[0]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD01L89YfDb9"
      },
      "source": [
        "a[0,:, :sentence.shape[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su6JX2lfgE6-",
        "outputId": "670c21cc-9cf1-4795-ca2c-440fe8346df1"
      },
      "source": [
        "attention.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGG9OL95giSE",
        "outputId": "1e13863c-ae72-45a1-f20e-3fb5d1963ead"
      },
      "source": [
        "attention[7]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3755067 , 0.01035687, 0.10788263, 0.14881349, 0.0342859 ,\n",
              "       0.21384533, 0.10930903], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj2wSUIQf5x3",
        "outputId": "cc508070-1fcf-4b9c-f024-d7cc7856f584"
      },
      "source": [
        "attention[7][:-1]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3755067 , 0.01035687, 0.10788263, 0.14881349, 0.0342859 ,\n",
              "       0.21384533], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE9xFuQ-h9gB",
        "outputId": "ca8bbeb8-24fe-4d56-a6f5-fd1f8ed23d29"
      },
      "source": [
        "result.numpy()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    1,     2,   728,     4,  6624,   135,    20,     9,    10,\n",
              "       16256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so2Gfe1bioK3",
        "outputId": "2be1a4d7-8789-4a35-ea78-24dc9099138d"
      },
      "source": [
        "len(attention)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzZLz5QOkQjd",
        "outputId": "c8c19f84-6d3c-4779-baa4-41e5e0d2b2e7"
      },
      "source": [
        "attention.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k4G_wmykadU",
        "outputId": "3afb0519-1bce-4ddf-e581-1b59de23bf0a"
      },
      "source": [
        "sentence.shape"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Udap8Suu7N",
        "outputId": "7dd6114c-39d1-431e-9643-ed5e42091b5e"
      },
      "source": [
        "result.shape"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV7xe5rillZ8",
        "outputId": "9923afec-d708-4352-9083-884268b5a75a"
      },
      "source": [
        "inp.numpy()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11453,     1,  1417,    25,   730,     4, 11454,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUywUhVlZeG"
      },
      "source": [
        "list(enumerate(zip(inp.numpy(), tar.numpy(), attn['decoder_layer4_block2'].numpy())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "xWvgga_MlFED",
        "outputId": "dbccc124-d545-45f2-fea7-54e4adb55ed9"
      },
      "source": [
        "len(list(enumerate(zip(inp.numpy(), tar.numpy(), attn['decoder_layer4_block2'].numpy())))[0][0])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-b8ab4bfc0f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_layer4_block2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAIK89nbmFR6"
      },
      "source": [
        " a[0,:, :sentence.shape[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SnoI0iRpXBr",
        "outputId": "31e0bcf3-1861-4320-887d-1476347d54c2"
      },
      "source": [
        "attention[0]"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00490534, 0.88131696, 0.0020767 , 0.00346318, 0.10490883,\n",
              "       0.002082  , 0.00124701, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF8cnsOtujsZ",
        "outputId": "b7427ec2-c21d-4333-eff7-ff3d0a1a39ff"
      },
      "source": [
        "attention.shape"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 119, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqciGsXVu9Pl",
        "outputId": "3207cf74-f167-4788-a775-a4c0a669ca3a"
      },
      "source": [
        "attn['decoder_layer4_block2'].numpy()[0,:, :sentence.shape[0]].shape"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 7, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiL2nXPgvyyg",
        "outputId": "47764e4a-20a1-44aa-8624-9bdd10fd1c20"
      },
      "source": [
        "sentence.shape"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMFL3SO5qavC",
        "outputId": "3a5983e0-ad9b-44a3-b4d3-341ada92871c"
      },
      "source": [
        "sentence"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=int64, numpy=array([11453,     1,  1417,    25,   730,     4, 11454])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "xPk87O9Fv70v",
        "outputId": "500a5d48-0baa-4751-c56d-c016ffccf5f8"
      },
      "source": [
        "for i, (s, t, a) in enumerate(zip(inp, tar, attn['decoder_layer4_block2'])):\n",
        "  sentence = tf.squeeze(s)[:tf.argmax(tf.squeeze(s)).numpy()+1]\n",
        "  print(a.shape)\n",
        "  #attention = a[0,:,:, :sentence.shape[0]]\n",
        "  attention = a[:,:, :sentence.shape[0]]\n",
        "  print(attention.shape)\n",
        "\n",
        "  result = tf.squeeze(t)[:tf.argmax(tf.squeeze(t)).numpy()+1][1:]\n",
        "  print(\"Input:\", ' '.join([train_dataset.source_index[i.numpy()] for i in sentence][1:-1]))\n",
        "  print(\"Output:\", ''.join([train_dataset.target_index[i.numpy()] for i in result][:-1]))\n",
        "  plot_attention_weight(sentence, attention, result)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 119, 60)\n",
            "(4, 119, 7)\n",
            "Input: Tom wants a cat .\n",
            "Output: トムは猫が飼いたいのよ。\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMR8Z_lpLEpg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "7e0c1953-0f90-44e4-ad60-f681d612f50a"
      },
      "source": [
        "\"\"\"\n",
        "for i, (s, t, a) in enumerate(zip(inp.values, tar.values, attn['decoder_layer4_block2'].values)):\n",
        "  sentence = tf.squeeze(s)[:tf.argmax(tf.squeeze(s)).numpy()+1]\n",
        "  attention = a[0,:, :, :sentence.shape[0]]\n",
        "  result = tf.squeeze(t)[:tf.argmax(tf.squeeze(t)).numpy()+1][1:]\n",
        "  print(\"Input:\", ' '.join([train_dataset.source_index[i.numpy()] for i in sentence][1:-1]))\n",
        "  print(\"Output:\", ''.join([train_dataset.target_index[i.numpy()] for i in result][:-1]))\n",
        "  plot_attention_weight(sentence, attention, result)\n",
        "\"\"\""
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-52cf15020101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_layer4_block2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'values'"
          ]
        }
      ]
    }
  ]
}